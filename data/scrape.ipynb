{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, itertools, httplib2, PyPDF2, shlex, signal, subprocess, requests, urllib.request, shutil\n",
    "from bs4 import BeautifulSoup\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from time import sleep\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = 180803\n",
    "bm = pd.read_csv(\"brainmap/experiments_%d.csv\" %date, header=0, index_col=None, encoding=\"cp858\")\n",
    "citations = open(\"brainmap/citations_%d.txt\" %date).readlines()\n",
    "coordinates = open(\"brainmap/coordinates_%d.txt\" %date).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract relevant data from experiments\n",
    "bm = bm[[\"BRAINMAP_ID\", \"YEAR\", \"1st_AUTHOR\", \"JOURNAL\", \"NUM_COORDINATES\", \"EXPERIMENT\", \"BEHAVIORAL_DOMAIN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Consolidate experiments within studies, summing the number of coordinates\n",
    "dic = {id: {\"NUM_COORDINATES\": 0, \"EXPERIMENT\": [], \"BEHAVIORAL_DOMAIN\": []} for id in sorted(list(set(bm[\"BRAINMAP_ID\"])))}\n",
    "for i, row in bm.iterrows():\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"YEAR\"] = row[\"YEAR\"]\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"1st_AUTHOR\"] = row[\"1st_AUTHOR\"]\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"JOURNAL\"] = row[\"JOURNAL\"]\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"NUM_COORDINATES\"] += row[\"NUM_COORDINATES\"]\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"EXPERIMENT\"].append(row[\"EXPERIMENT\"])\n",
    "    dic[row[\"BRAINMAP_ID\"]][\"BEHAVIORAL_DOMAIN\"].append(row[\"BEHAVIORAL_DOMAIN\"])\n",
    "bm = pd.DataFrame(dic).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add data from citations\n",
    "for splitter, study in itertools.groupby(citations, lambda line: line == \"\\n\"):\n",
    "    dic = {item.split()[0]: ' '.join(item.split()[1:]).strip() for item in list(study) if len(item.split()) > 1}\n",
    "    if \"%2\" in dic.keys():\n",
    "        id = int(dic[\"%2\"].split(\"= \")[1])\n",
    "        if \"%1\" in dic.keys():\n",
    "            bm.at[id,\"PMID\"] = dic[\"%1\"].split(\"= \")[1]\n",
    "        if \"%T\" in dic.keys():\n",
    "            bm.at[id,\"TITLE\"] = dic[\"%T\"]\n",
    "        if \"%A\" in dic.keys():\n",
    "            bm.at[id,\"AUTHORS\"] = dic[\"%A\"]\n",
    "        if \"%V\" in dic.keys():\n",
    "            bm.at[id,\"VOLUME\"] = dic[\"%V\"]\n",
    "        if \"%8\" in dic.keys():\n",
    "            bm.at[id,\"MONTH\"] = dic[\"%8\"].split()[0]\n",
    "        if \"%P\" in dic.keys():\n",
    "            bm.at[id,\"PAGES\"] = dic[\"%P\"]\n",
    "        if \"%Z\" in dic.keys():\n",
    "            bm.at[id,\"DESCRIPTION\"] = dic[\"%Z\"].split(\"= \")[1]\n",
    "        if \"%U\" in dic.keys():\n",
    "            bm.at[id,\"ABSTRACT_URL\"] = dic[\"%U\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute subject-author key for matching with coordinate data\n",
    "for i, row in bm.iterrows():\n",
    "    bm.at[i,\"KEY\"] = row[\"1st_AUTHOR\"] + \", \" + str(row[\"YEAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort columns\n",
    "bm.columns = list(bm.columns)\n",
    "bm = bm[[\"PMID\", \"KEY\", \"1st_AUTHOR\", \"AUTHORS\", \"YEAR\", \"TITLE\", \"JOURNAL\",\n",
    "        \"VOLUME\", \"MONTH\", \"PAGES\", \"BEHAVIORAL_DOMAIN\", \"EXPERIMENT\",\n",
    "        \"DESCRIPTION\", \"ABSTRACT_URL\", \"NUM_COORDINATES\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save metadata to file\n",
    "bm.to_csv(path_or_buf=\"brainmap/brainmap_metadata_180803.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload PMIDs from manually updated file\n",
    "coordinates = open(\"brainmap/coordinates_180803.txt\").readlines()\n",
    "bm = pd.read_csv(\"brainmap/brainmap_metadata_180809.csv\", header=0, index_col=None, encoding=\"cp858\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Match coordinates to PMIDs and sample sizes to BrainMap IDs\n",
    "coord, samp = {}, {}\n",
    "for splitter, study in itertools.groupby(coordinates, lambda line: line == \"\\n\"):\n",
    "    if not splitter:\n",
    "        study = list(study)\n",
    "        key = study[0].replace(\"// \", \"\").split(\": \")[0]\n",
    "        if key in list(bm[\"KEY\"]):\n",
    "            try:\n",
    "                pmid = int(bm.loc[bm[\"KEY\"] == key, \"PMID\"])\n",
    "                bmid = int(bm.loc[bm[\"KEY\"] == key, \"BRAINMAP_ID\"])\n",
    "            except:\n",
    "                print(key)\n",
    "            if pmid not in coord.keys():\n",
    "                coord[pmid] = []\n",
    "            for line in study:\n",
    "                if not line.startswith(\"//\"):\n",
    "                    coord[pmid].append(line.replace(\"\\t\", \",\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add sample sizes to metadata\n",
    "for bmid, val in samp.items():\n",
    "    bm.at[bmid,\"NUM_SUBJECTS\"] = val\n",
    "bm.to_csv(path_or_buf=\"brainmap/brainmap_metadata_180809b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save number of coordinates to BrainMap metadata \n",
    "# and subset by studies with coordinates\n",
    "for i, row in bm.iterrows():\n",
    "    if row[\"PMID\"] in coord.keys():\n",
    "        bm.at[i,\"NUM_COORDINATES\"] = len(coord[row[\"PMID\"]])\n",
    "bm_sub = bm.loc[bm[\"NUM_COORDINATES\"] > 0]\n",
    "bm_sub.to_csv(path_or_buf=\"brainmap/brainmap_metadata_180810.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = []\n",
    "for sigma in [5]:\n",
    "    \n",
    "    # Create directory for current smoothing sigma\n",
    "    if not os.path.exists(\"brainmap/brainmap_preproc_coords/{}mm\".format(sigma)):\n",
    "        os.makedirs(\"brainmap/brainmap_preproc_coords/{}mm\".format(sigma))\n",
    "    if not os.path.exists(\"brainmap/brainmap_preproc_coords/{}mm/logs\".format(sigma)):\n",
    "        os.makedirs(\"brainmap/brainmap_preproc_coords/{}mm/logs\".format(sigma))\n",
    "    \n",
    "    for pmid in list(bm[\"PMID\"]):\n",
    "        if pmid in coord.keys():\n",
    "\n",
    "            # Format preprocessing command\n",
    "            comm = \"pc.run_preproc(path, {}, {}, smoothing_sigma={}, mask_path=mask_path)\".format(coord[pmid], int(pmid), sigma)\n",
    "            \n",
    "            # Write python script with command for executing preprocessing\n",
    "            pyfile = open(\"brainmap/brainmap_preproc_coords/{}mm/preproc_{}.py\".format(sigma, int(pmid)), \"w+\")\n",
    "            pyfile.write(\"#!/bin/python\\n\\nimport preproc_coords as pc\\n\\npath = '/scratch/PI/aetkin/ebeam/cogneuro/brainmap'\\nmask_path = '/scratch/PI/aetkin/ebeam/cogneuro/masks'\\n\\n{}\".format(comm))\n",
    "            pyfile.close()\n",
    "            \n",
    "            # Scale script duration to number of coordinates\n",
    "            mins = 15*len(set(coord[pmid]))\n",
    "            qos = \"#\"\n",
    "            partition = \"normal\"\n",
    "            if mins > 600:\n",
    "                qos = \"#\"\n",
    "                partition = \"normal\"\n",
    "                long.append(pmid)\n",
    "\n",
    "            # Write bash script for slurm submission\n",
    "            bashfile = open(\"brainmap/brainmap_preproc_coords/{}mm/preproc_{}.sbatch\".format(sigma, int(pmid)), \"w+\")\n",
    "            lines = [\"#!/bin/bash\\n\",\n",
    "                     \"#SBATCH --job-name={}_{}\".format(sigma, int(pmid)),\n",
    "                     \"#SBATCH --output=logs/{}.%j.out\".format(int(pmid)),\n",
    "                     \"#SBATCH --error=logs/{}.%j.err\".format(int(pmid)),\n",
    "                     \"#SBATCH --time={}\".format(str(timedelta(minutes=mins)).replace(\"2 days, \", \"01-\").replace(\"1 day, \", \"01-\")),\n",
    "                     \"#SBATCH -p {}\".format(partition),\n",
    "                     \"{}#SBATCH --qos=long\".format(qos),\n",
    "                     \"#SBATCH --nodes=1\",\n",
    "                     \"#SBATCH --mem=350\",\n",
    "                     \"#SBATCH -c 1\",\n",
    "                     \"#SBATCH --mail-type=FAIL # notifications for job failure only\",\n",
    "                     \"#SBATCH --mail-user=ebeam@stanford.edu\\n\",\n",
    "                     \"module load python/2.7.13 biology fsl/5.0.10\",\n",
    "                     \"srun python preproc_{}.py\".format(int(pmid))]\n",
    "            for line in lines:\n",
    "                bashfile.write(line + \"\\n\")\n",
    "            bashfile.close()\n",
    "        \n",
    "        # Copy over preprocessing and wrap scripts\n",
    "        copyfile(\"brainmap/brainmap_preproc_coords/preproc_coords.py\", \"brainmap/brainmap_preproc_coords/{}mm/preproc_coords.py\".format(sigma))\n",
    "        copyfile(\"brainmap/brainmap_preproc_coords/wrap_{}mm.sh\".format(sigma), \"brainmap/brainmap_preproc_coords/{}mm/wrap.sh\".format(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to split list into list of n-sized chunks\n",
    "def chunkify(l, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(l), n):\n",
    "        chunks.append(l[i:i + n])\n",
    "    leftover = len(l)-(len(l)*n)\n",
    "    chunks.append(l[-leftover:])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = chunkify(list(bm[\"PMID\"]), 150)\n",
    "for sigma in [5]:\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        lines = [\"#!/bin/sh\", \n",
    "                 'IDS=\"{}\"'.format(\" \".join([str(id) for id in chunk])),\n",
    "                \"for ID in $IDS; do\",\n",
    "                \"if [ ! -f '/scratch/PI/aetkin/ebeam/cogneuro/brainmap/coordinates/5mm/${ID}.txt' ]\", \n",
    "                \"then\", \n",
    "                \"echo `sbatch preproc_${ID}.sbatch`\", \n",
    "                \"sleep 1\", \n",
    "                \"fi\", \n",
    "                \"done\"]\n",
    "        file = open(\"brainmap/brainmap_preproc_coords/{}mm/wrap_{}.sh\".format(sigma, i), \"w+\")\n",
    "        for line in lines:\n",
    "            file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3351"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMID to DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = pd.read_csv(\"brainmap/brainmap_metadata_180803.csv\", header=0, index_col=None, encoding=\"cp858\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(url, delay=0.0, verbose=False):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1464.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers, timeout=5.0)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12202083.0\n",
      "9025115.0\n",
      "15721961.0\n",
      "21427167.0\n"
     ]
    }
   ],
   "source": [
    "for i, row in bm.iterrows():\n",
    "    try:\n",
    "        text = get_url(\"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={}&retmode=text&rettype=medline\".format(row[\"PMID\"]))\n",
    "        for line in text.split(\"\\n\"):\n",
    "            if line.startswith(\"AID\"):\n",
    "                try:\n",
    "                    doi = line.split(\"- \")[1].replace(\" [doi]\",\"\").strip()\n",
    "                    bm.at[i,\"DOI\"] = doi\n",
    "                except:\n",
    "                    print(row[\"PMID\"])\n",
    "    except:\n",
    "        print(row[\"PMID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm.to_csv(path_or_buf=\"brainmap/brainmap_metadata_180803.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = pd.read_csv(\"brainmap/brainmap_metadata_180804.csv\", header=0, index_col=None, encoding=\"cp858\")\n",
    "pmids = [pmid for pmid in bm[\"PMID\"] if not np.isnan(pmid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download PloS One articles\n",
    "http = httplib2.Http(\".cache\", disable_ssl_certificate_validation = True)\n",
    "for i, row in bm.iterrows():\n",
    "    if row[\"JOURNAL\"] == \"PloS one\" and not np.isnan(row[\"PMID\"]):\n",
    "        print(\"Downloading PDF for {}\".format(row[\"id\"]))\n",
    "        pdf_url = \"http://journals.plos.org/plosone/article/file?id={}&type=printable\".format(row[\"doi\"])\n",
    "        pdf_file = \"pdf/{}.pdf\".format(row[\"PMID\"])\n",
    "        comm = \"wget -O {} {}\".format(pdf_file, pdf_url)\n",
    "        args = shlex.split(comm)\n",
    "        proc = subprocess.call(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt download with ruby script\n",
    "for pmid in pmids:\n",
    "    try:\n",
    "        cogneuro_file = \"../texts/pdf/{}.pdf\".format(int(pmid))\n",
    "        pubmed_file = \"../../pubmed/vetted/{}.pdf\".format(int(pmid))\n",
    "        if not os.path.isfile(cogneuro_file):\n",
    "            if os.path.isfile(pubmed_file):\n",
    "                shutil.move(pubmed_file, cogneuro_file)\n",
    "            else:\n",
    "                comm = \"ruby /Users/ehbeam/Dropbox/Stanford/Research/Projects/Psychiatlas/scripts/borrowed/Pubmed-Batch-Download-master/pubmedid2pdf.rb {}\".format(int(pmid))\n",
    "                args = shlex.split(comm)\n",
    "                proc = subprocess.call(args)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty PDF for 8989012\n",
      "Removed empty PDF for 9051780\n",
      "Removed empty PDF for 9141092\n",
      "Removed empty PDF for 9462480\n",
      "Removed empty PDF for 9665617\n",
      "Removed empty PDF for 9674604\n",
      "Removed empty PDF for 9696465\n",
      "Removed corrupt PDF for 10372081\n",
      "Removed empty PDF for 10380965\n",
      "Removed empty PDF for 10568854\n",
      "Removed empty PDF for 10923655\n",
      "Removed empty PDF for 11201097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty PDF for 12151759\n",
      "Removed empty PDF for 12195096\n",
      "Removed empty PDF for 12634477\n",
      "Removed empty PDF for 12692460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty PDF for 12858037\n",
      "Removed empty PDF for 12858037\n",
      "Removed empty PDF for 14561934\n",
      "Removed empty PDF for 14625454\n",
      "Removed empty PDF for 14625459\n",
      "Removed empty PDF for 15073516\n",
      "Removed empty PDF for 15570157\n",
      "Removed empty PDF for 15597038\n",
      "Removed empty PDF for 15973144\n",
      "Removed empty PDF for 16237317\n",
      "Removed empty PDF for 16237324\n",
      "Removed empty PDF for 16513004\n",
      "Removed empty PDF for 16603917\n",
      "Removed empty PDF for 16790655\n",
      "Removed empty PDF for 17471059\n",
      "Removed empty PDF for 17545731\n",
      "Removed empty PDF for 18158370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty PDF for 18797307\n",
      "Removed empty PDF for 18797310\n",
      "Removed empty PDF for 19218875\n",
      "Removed empty PDF for 19339907\n",
      "Removed empty PDF for 19512976\n",
      "Removed empty PDF for 19617860\n",
      "Removed empty PDF for 20300040\n",
      "Removed empty PDF for 20508544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty PDF for 22048836\n",
      "Removed empty PDF for 26962820\n"
     ]
    }
   ],
   "source": [
    "# Second-pass attempt to download\n",
    "http = httplib2.Http(\".cache\", disable_ssl_certificate_validation = True)\n",
    "import requests\n",
    "for pmid in pmids:\n",
    "    if not os.path.isfile(\"../texts/pdf/{}.pdf\".format(int(pmid))):\n",
    "\n",
    "        # Insert the Medline ID into the PubMed entrez url\n",
    "        try:\n",
    "            url = \"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(int(pmid))\n",
    "            pdf_url = \"\"\n",
    "\n",
    "            # Attempt to download pdf\n",
    "            response = requests.get(url).text\n",
    "            for line in str(response).split():\n",
    "                if \"http\" in line and \"pdf\" in line:\n",
    "                    pdf_url = line.split('\"')[1]\n",
    "                    pdf_file = \"pdf/{}.pdf\".format(int(pmid))\n",
    "                    comm = \"wget -O {} {}\".format(pdf_file, pdf_url)\n",
    "                    args = shlex.split(comm)\n",
    "                    proc = subprocess.call(args)\n",
    "            sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Wait for PDF to download, then remove if corrupt\n",
    "        try:\n",
    "            if os.path.getsize(pdf_file) == 0:\n",
    "                os.remove(pdf_file)\n",
    "                print(\"Removed empty PDF for {}\".format(int(pmid)))\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    PyPDF2.PdfFileReader(open(pdf_file, \"rb\"))\n",
    "                except PyPDF2.utils.PdfReadError:\n",
    "                    os.remove(pdf_file)\n",
    "                    print(\"Removed corrupt PDF for {}\".format(int(pmid)))\n",
    "                    continue\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "# Identify missing PDFs\n",
    "downloaded = [int(file.replace(\".pdf\", \"\")) for file in os.listdir(\"../texts/pdf\") if not file.startswith(\".\")]\n",
    "missing = [int(pmid) for pmid in pmids if int(pmid) not in downloaded]\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../brainmap/texts/pdfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-21acc9fe5a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copy over missing pdfs from prior dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprior_pdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../brainmap/texts/pdfs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpmid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpmid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprior_pdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../brainmap/texts/pdfs/{}.pdf\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pdf/{}.pdf\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../brainmap/texts/pdfs'"
     ]
    }
   ],
   "source": [
    "# Copy over missing pdfs from prior dataset\n",
    "prior_pdfs = [int(file.replace(\".pdf\", \"\")) for file in os.listdir(\"../../brainmap/texts/pdfs\") if not file.startswith(\".\")]\n",
    "for pmid in missing:\n",
    "    if pmid in prior_pdfs:\n",
    "        copyfile(\"../../brainmap/texts/pdfs/{}.pdf\".format(pmid), \"pdf/{}.pdf\".format(pmid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save list of missing PDFs with URL for download\n",
    "missing_url = [\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(pmid) for pmid in missing]\n",
    "missing_df = pd.DataFrame({\"URL\": missing_url, \"PMID\": missing})\n",
    "missing_df.to_csv(path_or_buf=\"../texts/download/failed_pdfs_bm.csv\", index=None, columns=[\"URL\",\"PMID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurosynth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14371"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load most recent data release (July 2018)\n",
    "ns18 = pd.read_csv(\"neurosynth/neurosynth_180712.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ns18[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11233"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load prior data release, which includes manually updated space information (July 2015)\n",
    "ns15 = pd.read_csv(\"neurosynth/neurosynth_180623.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ns15[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11406"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load prior data release, without updated space information (July 2015)\n",
    "ns15_raw = pd.read_csv(\"neurosynth/neurosynth_180623_raw.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ns15_raw[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ACE data\n",
    "ace = pd.read_csv(\"ace/ace_180711.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ace[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53878"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count up rows with unknown space in new data\n",
    "len(ns18[ns18[\"space\"] == \"UNKNOWN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add missing space information to new data\n",
    "for i, r in ns18.iterrows():\n",
    "    if r[\"space\"] == \"UNKNOWN\":\n",
    "        space = ns15.loc[(ns15[\"id\"] == r[\"id\"]) & (ns15[\"x\"] == r[\"x\"]) & (ns15[\"y\"] == r[\"y\"]) & (ns15[\"z\"] == r[\"z\"]), \"space\"].values\n",
    "        if len(space) > 0:\n",
    "            ns18.set_value(i, \"space\", space[0])\n",
    "        else:\n",
    "            ace_space = ace.loc[(ace[\"id\"] == r[\"id\"]) & (ace[\"x\"] == r[\"x\"]) & (ace[\"y\"] == r[\"y\"]) & (ace[\"z\"] == r[\"z\"]), \"space\"].values\n",
    "            raw_space = ns15_raw.loc[(ns15_raw[\"id\"] == r[\"id\"]) & (ns15_raw[\"x\"] == r[\"x\"]) & (ns15_raw[\"y\"] == r[\"y\"]) & (ns15_raw[\"z\"] == r[\"z\"]), \"space\"].values\n",
    "            if len(ace_space) > 0:\n",
    "                if ace_space[0] != \"UNKNOWN\":\n",
    "                    ns18.set_value(i, \"space\", ace_space[0])\n",
    "                elif ace_space[0] == \"UNKNOWN\":\n",
    "                    ns18.set_value(i, \"space\", \"DISCARD\")\n",
    "            elif len(raw_space) > 0:\n",
    "                if raw_space[0] == \"UNKNOWN\":\n",
    "                    ns18.set_value(i, \"space\", \"DISCARD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6533"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recount rows with unknown space\n",
    "len(ns18[ns18[\"space\"] == \"UNKNOWN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3349"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count rows with known unknown space to be discarded\n",
    "len(ns18[ns18[\"space\"] == \"DISCARD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save new data with filled in space information\n",
    "ns18.to_csv(\"neurosynth/neurosynth_180713.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF for 17183636\n",
      "Downloading PDF for 17327919\n",
      "Downloading PDF for 17389911\n",
      "Downloading PDF for 17579718\n",
      "Downloading PDF for 17712410\n",
      "Downloading PDF for 17849020\n",
      "Downloading PDF for 17971871\n",
      "Downloading PDF for 18231575\n",
      "Downloading PDF for 18301756\n",
      "Downloading PDF for 18335036\n",
      "Downloading PDF for 18365029\n",
      "Downloading PDF for 18493621\n",
      "Downloading PDF for 18509462\n",
      "Downloading PDF for 18523591\n",
      "Downloading PDF for 18682729\n",
      "Downloading PDF for 18698355\n",
      "Downloading PDF for 18728773\n",
      "Downloading PDF for 18769538\n",
      "Downloading PDF for 18797499\n",
      "Downloading PDF for 18827897\n",
      "Downloading PDF for 18846222\n",
      "Downloading PDF for 18958158\n",
      "Downloading PDF for 18958161\n",
      "Downloading PDF for 18985147\n",
      "Downloading PDF for 19018279\n",
      "Downloading PDF for 19030105\n",
      "Downloading PDF for 19050764\n",
      "Downloading PDF for 19517024\n",
      "Downloading PDF for 19584921\n",
      "Downloading PDF for 19636426\n",
      "Downloading PDF for 19672296\n",
      "Downloading PDF for 19680553\n",
      "Downloading PDF for 19707568\n",
      "Downloading PDF for 19750227\n",
      "Downloading PDF for 19771159\n",
      "Downloading PDF for 19826471\n",
      "Downloading PDF for 20011541\n",
      "Downloading PDF for 20084170\n",
      "Downloading PDF for 20179758\n",
      "Downloading PDF for 20300635\n",
      "Downloading PDF for 20419095\n",
      "Downloading PDF for 20520767\n",
      "Downloading PDF for 20838644\n",
      "Downloading PDF for 21151556\n",
      "Downloading PDF for 21179436\n",
      "Downloading PDF for 21179564\n",
      "Downloading PDF for 21203474\n",
      "Downloading PDF for 21267080\n",
      "Downloading PDF for 21283580\n",
      "Downloading PDF for 21298074\n",
      "Downloading PDF for 21364890\n",
      "Downloading PDF for 21412428\n",
      "Downloading PDF for 21533250\n",
      "Downloading PDF for 21589884\n",
      "Downloading PDF for 21625502\n",
      "Downloading PDF for 21687636\n",
      "Downloading PDF for 21695133\n",
      "Downloading PDF for 21738657\n",
      "Downloading PDF for 21738725\n",
      "Downloading PDF for 21799807\n",
      "Downloading PDF for 21818386\n",
      "Downloading PDF for 21829564\n",
      "Downloading PDF for 21935394\n",
      "Downloading PDF for 21935483\n",
      "Downloading PDF for 21949675\n",
      "Downloading PDF for 21949769\n",
      "Downloading PDF for 22022589\n",
      "Downloading PDF for 22073183\n",
      "Downloading PDF for 22110619\n",
      "Downloading PDF for 22110623\n",
      "Downloading PDF for 22110714\n",
      "Downloading PDF for 22132137\n",
      "Downloading PDF for 22174872\n",
      "Downloading PDF for 22174900\n",
      "Downloading PDF for 22216234\n",
      "Downloading PDF for 22216252\n",
      "Downloading PDF for 22216274\n",
      "Downloading PDF for 22238630\n",
      "Downloading PDF for 22238671\n",
      "Downloading PDF for 22276111\n",
      "Downloading PDF for 22319604\n",
      "Downloading PDF for 22319607\n",
      "Downloading PDF for 22355309\n",
      "Downloading PDF for 22412928\n",
      "Downloading PDF for 22442733\n",
      "Downloading PDF for 22479499\n",
      "Downloading PDF for 22479551\n",
      "Downloading PDF for 22532832\n",
      "Downloading PDF for 22563478\n",
      "Downloading PDF for 22570705\n",
      "Downloading PDF for 22574141\n",
      "Downloading PDF for 22666470\n",
      "Downloading PDF for 22693600\n",
      "Downloading PDF for 22693639\n",
      "Downloading PDF for 22701655\n",
      "Downloading PDF for 22745745\n",
      "Downloading PDF for 22761887\n",
      "Downloading PDF for 22815825\n",
      "Downloading PDF for 22815889\n",
      "Downloading PDF for 22848586\n",
      "Downloading PDF for 22911806\n",
      "Downloading PDF for 22912698\n",
      "Downloading PDF for 22916139\n",
      "Downloading PDF for 22928000\n",
      "Downloading PDF for 22937001\n",
      "Downloading PDF for 22937041\n",
      "Downloading PDF for 22952599\n",
      "Downloading PDF for 23028661\n",
      "Downloading PDF for 23028774\n",
      "Downloading PDF for 23028892\n",
      "Downloading PDF for 23029097\n",
      "Downloading PDF for 23056477\n",
      "Downloading PDF for 23110158\n",
      "Downloading PDF for 23133615\n",
      "Downloading PDF for 23144849\n",
      "Downloading PDF for 23145011\n",
      "Downloading PDF for 23152865\n",
      "Downloading PDF for 23155368\n",
      "Downloading PDF for 23155380\n",
      "Downloading PDF for 23155450\n",
      "Downloading PDF for 23185300\n",
      "Downloading PDF for 23185306\n",
      "Downloading PDF for 23185425\n",
      "Downloading PDF for 23185566\n",
      "Downloading PDF for 23209584\n",
      "Downloading PDF for 23209599\n",
      "Downloading PDF for 23209643\n",
      "Downloading PDF for 23251653\n",
      "Downloading PDF for 23285070\n",
      "Downloading PDF for 23285086\n",
      "Downloading PDF for 23300517\n",
      "Downloading PDF for 23342176\n",
      "Downloading PDF for 23372641\n",
      "Downloading PDF for 23382821\n",
      "Downloading PDF for 23383244\n",
      "Downloading PDF for 23437284\n",
      "Downloading PDF for 23457466\n",
      "Downloading PDF for 23460913\n",
      "Downloading PDF for 23483911\n",
      "Downloading PDF for 23505435\n",
      "Downloading PDF for 23555020\n",
      "Downloading PDF for 23555827\n",
      "Downloading PDF for 23573184\n",
      "Downloading PDF for 23675408\n",
      "Downloading PDF for 23696798\n",
      "Downloading PDF for 23734238\n",
      "Downloading PDF for 23824302\n",
      "Downloading PDF for 23826388\n",
      "Downloading PDF for 23936077\n",
      "Downloading PDF for 23991064\n",
      "Downloading PDF for 24015241\n",
      "Downloading PDF for 24019938\n",
      "Downloading PDF for 24023609\n",
      "Downloading PDF for 24023940\n",
      "Downloading PDF for 24039715\n",
      "Downloading PDF for 24040007\n",
      "Downloading PDF for 24040104\n",
      "Downloading PDF for 24040118\n",
      "Downloading PDF for 24040178\n",
      "Downloading PDF for 24040207\n",
      "Downloading PDF for 24040262\n",
      "Downloading PDF for 24058456\n",
      "Downloading PDF for 24058706\n",
      "Downloading PDF for 24069223\n",
      "Downloading PDF for 24069368\n",
      "Downloading PDF for 24069414\n",
      "Downloading PDF for 24086291\n",
      "Downloading PDF for 24086358\n",
      "Downloading PDF for 24086409\n",
      "Downloading PDF for 24086531\n",
      "Downloading PDF for 24086664\n",
      "Downloading PDF for 24086758\n",
      "Downloading PDF for 24098513\n",
      "Downloading PDF for 24098688\n",
      "Downloading PDF for 24124475\n",
      "Downloading PDF for 24124576\n",
      "Downloading PDF for 24130761\n",
      "Downloading PDF for 24155952\n",
      "Downloading PDF for 24167610\n",
      "Downloading PDF for 24194828\n",
      "Downloading PDF for 24204812\n",
      "Downloading PDF for 24205088\n",
      "Downloading PDF for 24205198\n",
      "Downloading PDF for 24205247\n",
      "Downloading PDF for 24205327\n",
      "Downloading PDF for 24205330\n",
      "Downloading PDF for 24223847\n",
      "Downloading PDF for 24223850\n",
      "Downloading PDF for 24224044\n",
      "Downloading PDF for 24224053\n",
      "Downloading PDF for 24236043\n",
      "Downloading PDF for 24236212\n",
      "Downloading PDF for 24244633\n",
      "Downloading PDF for 24260420\n",
      "Downloading PDF for 24265801\n",
      "Downloading PDF for 24278126\n",
      "Downloading PDF for 24312166\n",
      "Downloading PDF for 24312382\n",
      "Downloading PDF for 24324588\n",
      "Downloading PDF for 24324679\n",
      "Downloading PDF for 24324753\n",
      "Downloading PDF for 24324781\n",
      "Downloading PDF for 24340037\n",
      "Downloading PDF for 24348991\n",
      "Downloading PDF for 24349161\n",
      "Downloading PDF for 24349280\n",
      "Downloading PDF for 24349515\n",
      "Downloading PDF for 24358198\n",
      "Downloading PDF for 24358320\n",
      "Downloading PDF for 24358367\n",
      "Downloading PDF for 24367494\n",
      "Downloading PDF for 24367516\n",
      "Downloading PDF for 24367642\n",
      "Downloading PDF for 24367675\n",
      "Downloading PDF for 24376705\n",
      "Downloading PDF for 24376780\n",
      "Downloading PDF for 24386327\n",
      "Downloading PDF for 24391713\n",
      "Downloading PDF for 24391871\n",
      "Downloading PDF for 24392092\n",
      "Downloading PDF for 24400079\n",
      "Downloading PDF for 24404185\n",
      "Downloading PDF for 24409308\n",
      "Downloading PDF for 24416222\n",
      "Downloading PDF for 24416229\n",
      "Downloading PDF for 24416273\n",
      "Downloading PDF for 24416347\n",
      "Downloading PDF for 24416367\n",
      "Downloading PDF for 24416397\n",
      "Downloading PDF for 24427267\n",
      "Downloading PDF for 24427269\n",
      "Downloading PDF for 24454765\n",
      "Downloading PDF for 24454814\n",
      "Downloading PDF for 24454868\n",
      "Downloading PDF for 24454951\n",
      "Downloading PDF for 24465375\n",
      "Downloading PDF for 24465445\n",
      "Downloading PDF for 24465469\n",
      "Downloading PDF for 24465577\n",
      "Downloading PDF for 24465794\n",
      "Downloading PDF for 24465965\n",
      "Downloading PDF for 24466026\n",
      "Downloading PDF for 24466193\n",
      "Downloading PDF for 24475058\n",
      "Downloading PDF for 24475078\n",
      "Downloading PDF for 24475100\n",
      "Downloading PDF for 24475211\n",
      "Downloading PDF for 24475262\n",
      "Downloading PDF for 24475313\n",
      "Downloading PDF for 24498012\n",
      "Downloading PDF for 24498389\n",
      "Downloading PDF for 24505303\n",
      "Downloading PDF for 24505314\n",
      "Downloading PDF for 24505434\n",
      "Downloading PDF for 24505440\n",
      "Downloading PDF for 24516545\n",
      "Downloading PDF for 24594508\n",
      "Downloading PDF for 24598769\n",
      "Downloading PDF for 24647353\n",
      "Downloading PDF for 24663245\n",
      "Downloading PDF for 24667541\n",
      "Downloading PDF for 24682003\n",
      "Downloading PDF for 24739875\n",
      "Downloading PDF for 24743801\n",
      "Downloading PDF for 24835267\n",
      "Downloading PDF for 24911053\n",
      "Downloading PDF for 24937544\n",
      "Downloading PDF for 25140705\n",
      "Downloading PDF for 25162716\n",
      "Downloading PDF for 25188200\n",
      "Downloading PDF for 25191858\n",
      "Downloading PDF for 25226172\n",
      "Downloading PDF for 25271846\n",
      "Downloading PDF for 25369523\n",
      "Downloading PDF for 25376010\n",
      "Downloading PDF for 25396416\n",
      "Downloading PDF for 25438043\n",
      "Downloading PDF for 25438046\n",
      "Downloading PDF for 25463618\n",
      "Downloading PDF for 25479196\n",
      "Downloading PDF for 25502215\n",
      "Downloading PDF for 25502775\n",
      "Downloading PDF for 25514366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF for 25603126\n",
      "Downloading PDF for 25625285\n",
      "Downloading PDF for 25629899\n",
      "Downloading PDF for 25659130\n",
      "Downloading PDF for 25671563\n",
      "Downloading PDF for 25774886\n",
      "Downloading PDF for 25774979\n",
      "Downloading PDF for 25790002\n",
      "Downloading PDF for 25793718\n",
      "Downloading PDF for 25811453\n",
      "Downloading PDF for 25859660\n",
      "Downloading PDF for 25875000\n",
      "Downloading PDF for 25875594\n",
      "Downloading PDF for 25885897\n",
      "Downloading PDF for 25938442\n",
      "Downloading PDF for 25945925\n",
      "Downloading PDF for 25996480\n",
      "Downloading PDF for 26053316\n",
      "Downloading PDF for 26061877\n",
      "Downloading PDF for 26079805\n",
      "Downloading PDF for 26301900\n",
      "Downloading PDF for 26727514\n",
      "Downloading PDF for 27010196\n",
      "Downloading PDF for 27414048\n",
      "Downloading PDF for 27560361\n"
     ]
    }
   ],
   "source": [
    "# Download PloS One articles by DOI\n",
    "http = httplib2.Http(\".cache\", disable_ssl_certificate_validation = True)\n",
    "added = []\n",
    "for i, row in ns18.iterrows():\n",
    "    if row[\"journal\"] == \"PloS one\":\n",
    "        if row[\"id\"] not in added and \"{}.pdf\".format(row[\"id\"]) not in os.listdir(\"pdf\"):\n",
    "            print(\"Downloading PDF for {}\".format(row[\"id\"]))\n",
    "            pdf_url = \"http://journals.plos.org/plosone/article/file?id={}&type=printable\".format(row[\"doi\"])\n",
    "            pdf_file = \"pdf/{}.pdf\".format(row[\"id\"])\n",
    "            comm = \"wget -O {} {}\".format(pdf_file, pdf_url)\n",
    "            args = shlex.split(comm)\n",
    "            proc = subprocess.call(args)\n",
    "            added.append(row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt download with ruby script\n",
    "for pmid in list(set(ns18[\"id\"])):\n",
    "    if not os.path.isfile(\"../texts/pdf/{}.pdf\".format(pmid)):\n",
    "        comm = \"ruby /Users/ehbeam/Dropbox/Stanford/Research/Projects/Psychiatlas/scripts/borrowed/Pubmed-Batch-Download-master/pubmedid2pdf.rb {}\".format(pmid)\n",
    "        args = shlex.split(comm)\n",
    "        proc = subprocess.call(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Identify missing PDFs (note data were updated below)\n",
    "ns = pd.read_csv(\"neurosynth/neurosynth_180716.csv\", index_col=None, header=0)\n",
    "downloaded = [int(file.replace(\".pdf\", \"\")) for file in os.listdir(\"../texts/pdf\") if not file.startswith(\".\")]\n",
    "missing = [pmid for pmid in list(set(ns[\"id\"])) if pmid not in downloaded]\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save list of missing PDFs with URL for download\n",
    "missing_url = [\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(pmid) for pmid in missing]\n",
    "missing_df = pd.DataFrame({\"URL\": missing_url, \"PMID\": missing})\n",
    "missing_df.to_csv(path_or_buf=\"../texts/failed_pdfs_ns.csv\", index=None, columns=[\"URL\",\"PMID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = pd.read_csv(\"neurosynth/neurosynth_180716.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ns[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14147"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop coordinates in an unknown space\n",
    "ns = ns[ns[\"space\"] != \"UNKNOWN\"]\n",
    "ns = ns[ns[\"space\"] != \"DISCARD\"]\n",
    "len(list(set(list(ns[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index to eliminate dropped lines\n",
    "ns.index = range(len(ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add column for MNI coordinates\n",
    "ns[\"mni_coord\"] = ns[\"x\"].map(str) + \",\" + ns[\"y\"].map(str) + \",\" + ns[\"z\"].map(str)\n",
    "ns.loc[ns.space != \"MNI\", [\"mni_coord\"]] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to convert Talairach coordinates to MNI space\n",
    "# Adapted from https://github.com/neurosynth/neurosynth/blob/master/neurosynth/base/transformations.py\n",
    "\n",
    "def transform(foci, mat):\n",
    "    \"\"\" Convert coordinates from one space to another using provided\n",
    "    transformation matrix. \"\"\"\n",
    "    t = linalg.pinv(mat)\n",
    "    foci = np.hstack((foci, np.ones((foci.shape[0], 1))))\n",
    "    return np.dot(foci, t)[:, 0:3]\n",
    "\n",
    "def t88_to_mni():\n",
    "    \"\"\" Convert Talairach to MNI coordinates using the Lancaster transform.\n",
    "    Adapted from BrainMap scripts; see http://brainmap.org/icbm2tal/\n",
    "    Details are described in Lancaster et al. (2007)\n",
    "    (http://brainmap.org/new/pubs/LancasterHBM07.pdf). \"\"\"\n",
    "    return np.array([[0.9254, 0.0024, -0.0118, -1.0207],\n",
    "                     [-0.0048, 0.9316, -0.0871, -1.7667],\n",
    "                     [0.0152, 0.0883, 0.8924, 4.0926],\n",
    "                     [0.0, 0.0, 0.0, 1.0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>space</th>\n",
       "      <th>peak_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_num</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>mni_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397839</th>\n",
       "      <td>9185551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>548701</td>\n",
       "      <td>28699</td>\n",
       "      <td>3</td>\n",
       "      <td>A role for the right anterior temporal lobe in...</td>\n",
       "      <td>Small DM, Jones-Gotman M, Zatorre RJ, Petrides...</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Journal of neuroscience : the official jou...</td>\n",
       "      <td>18.975472613463868,38.79753000971181,-31.15962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397840</th>\n",
       "      <td>9185551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>548702</td>\n",
       "      <td>28699</td>\n",
       "      <td>3</td>\n",
       "      <td>A role for the right anterior temporal lobe in...</td>\n",
       "      <td>Small DM, Jones-Gotman M, Zatorre RJ, Petrides...</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Journal of neuroscience : the official jou...</td>\n",
       "      <td>30.967127226778764,51.681125243160615,-20.3123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397841</th>\n",
       "      <td>9185551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>548703</td>\n",
       "      <td>28699</td>\n",
       "      <td>3</td>\n",
       "      <td>A role for the right anterior temporal lobe in...</td>\n",
       "      <td>Small DM, Jones-Gotman M, Zatorre RJ, Petrides...</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Journal of neuroscience : the official jou...</td>\n",
       "      <td>10.218962457576001,42.29431987922428,-39.20048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397842</th>\n",
       "      <td>9185551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>548704</td>\n",
       "      <td>28699</td>\n",
       "      <td>3</td>\n",
       "      <td>A role for the right anterior temporal lobe in...</td>\n",
       "      <td>Small DM, Jones-Gotman M, Zatorre RJ, Petrides...</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Journal of neuroscience : the official jou...</td>\n",
       "      <td>-21.963194872504793,38.420005679102495,-21.460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397843</th>\n",
       "      <td>9185551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>548705</td>\n",
       "      <td>28699</td>\n",
       "      <td>3</td>\n",
       "      <td>A role for the right anterior temporal lobe in...</td>\n",
       "      <td>Small DM, Jones-Gotman M, Zatorre RJ, Petrides...</td>\n",
       "      <td>1997</td>\n",
       "      <td>The Journal of neuroscience : the official jou...</td>\n",
       "      <td>-27.41963359173434,30.33283250836168,-27.29068...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  doi     x     y     z space  peak_id  table_id table_num  \\\n",
       "397839  9185551  NaN  17.0  37.0 -20.0   TAL   548701     28699         3   \n",
       "397840  9185551  NaN  28.0  48.0  -9.0   TAL   548702     28699         3   \n",
       "397841  9185551  NaN   9.0  41.0 -27.0   TAL   548703     28699         3   \n",
       "397842  9185551  NaN -21.0  36.0 -12.0   TAL   548704     28699         3   \n",
       "397843  9185551  NaN -26.0  29.0 -18.0   TAL   548705     28699         3   \n",
       "\n",
       "                                                    title  \\\n",
       "397839  A role for the right anterior temporal lobe in...   \n",
       "397840  A role for the right anterior temporal lobe in...   \n",
       "397841  A role for the right anterior temporal lobe in...   \n",
       "397842  A role for the right anterior temporal lobe in...   \n",
       "397843  A role for the right anterior temporal lobe in...   \n",
       "\n",
       "                                                  authors  year  \\\n",
       "397839  Small DM, Jones-Gotman M, Zatorre RJ, Petrides...  1997   \n",
       "397840  Small DM, Jones-Gotman M, Zatorre RJ, Petrides...  1997   \n",
       "397841  Small DM, Jones-Gotman M, Zatorre RJ, Petrides...  1997   \n",
       "397842  Small DM, Jones-Gotman M, Zatorre RJ, Petrides...  1997   \n",
       "397843  Small DM, Jones-Gotman M, Zatorre RJ, Petrides...  1997   \n",
       "\n",
       "                                                  journal  \\\n",
       "397839  The Journal of neuroscience : the official jou...   \n",
       "397840  The Journal of neuroscience : the official jou...   \n",
       "397841  The Journal of neuroscience : the official jou...   \n",
       "397842  The Journal of neuroscience : the official jou...   \n",
       "397843  The Journal of neuroscience : the official jou...   \n",
       "\n",
       "                                                mni_coord  \n",
       "397839  18.975472613463868,38.79753000971181,-31.15962...  \n",
       "397840  30.967127226778764,51.681125243160615,-20.3123...  \n",
       "397841  10.218962457576001,42.29431987922428,-39.20048...  \n",
       "397842  -21.963194872504793,38.420005679102495,-21.460...  \n",
       "397843  -27.41963359173434,30.33283250836168,-27.29068...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Talairach coordinates to MNI space by Lancaster transform\n",
    "tal2mni = transform(ns[['x', 'y', 'z']].values, t88_to_mni())\n",
    "tal2mni_ser = pd.Series([str(row[0]) + \",\" + str(row[1]) + \",\" + str(row[2]) for row in tal2mni])\n",
    "ns.loc[ns[\"space\"] == \"TAL\", \"mni_coord\"] = tal2mni_ser\n",
    "ns[ns[\"space\"] == \"TAL\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save metadata with transformed coordinates\n",
    "ns.to_csv(path_or_buf=\"neurosynth/neurosynth_180805.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write scripts to preprocess coordinates\n",
    "ns = pd.read_csv(\"neurosynth/neurosynth_180805.csv\", index_col=None, header=0)\n",
    "long = []\n",
    "for sigma in [5]:#[0, 5]:\n",
    "    \n",
    "    # Create directory for current smoothing sigma\n",
    "    if not os.path.exists(\"neurosynth/neurosynth_preproc_coords/{}mm\".format(sigma)):\n",
    "        os.makedirs(\"neurosynth/neurosynth_preproc_coords/{}mm\".format(sigma))\n",
    "    if not os.path.exists(\"neurosynth/neurosynth_preproc_coords/{}mm/logs\".format(sigma)):\n",
    "        os.makedirs(\"neurosynth/neurosynth_preproc_coords/{}mm/logs\".format(sigma))\n",
    "    \n",
    "    for pmid in list(set(list(ns[\"id\"]))):\n",
    "\n",
    "        # Format preprocessing command\n",
    "        coords = list(ns[ns[\"id\"] == pmid][\"mni_coord\"])\n",
    "        comm = \"pc.run_preproc(path, {}, {}, smoothing_sigma={}, mask_path=mask_path)\".format(coords, pmid, sigma)\n",
    "\n",
    "        # Write python script with command for executing preprocessing\n",
    "        pyfile = open(\"neurosynth/neurosynth_preproc_coords/{}mm/preproc_{}.py\".format(sigma, pmid), \"w+\")\n",
    "        pyfile.write(\"#!/bin/python\\n\\nimport preproc_coords as pc\\n\\npath = '/scratch/PI/aetkin/ebeam/cogneuro/neurosynth'\\nmask_path = '/scratch/PI/aetkin/ebeam/cogneuro/masks'\\n\\n{}\".format(comm))\n",
    "        pyfile.close()\n",
    "        \n",
    "        # Scale script duration to number of coordinates\n",
    "        mins = 10*len(set(coords))\n",
    "        qos = \"#\"\n",
    "        partition = \"normal\"\n",
    "        if mins > 600:\n",
    "            qos = \"\"\n",
    "            partition = \"normal\"\n",
    "            long.append(pmid)\n",
    "\n",
    "        # Write bash script for slurm submission\n",
    "        bashfile = open(\"neurosynth/neurosynth_preproc_coords/{}mm/preproc_{}.sbatch\".format(sigma, pmid), \"w+\")\n",
    "        lines = [\"#!/bin/bash\\n\",\n",
    "                 \"#SBATCH --job-name={}_{}_ns\".format(pmid, sigma),\n",
    "                 \"#SBATCH --output=logs/{}.%j.out\".format(pmid),\n",
    "                 \"#SBATCH --error=logs/{}.%j.err\".format(pmid),\n",
    "                 \"#SBATCH --time={}\".format(str(timedelta(minutes=mins)).replace(\"1 day, \", \"01-\")),\n",
    "                 \"#SBATCH -p {}\".format(partition),\n",
    "                 \"{}#SBATCH --qos=long\".format(qos),\n",
    "                 \"#SBATCH --nodes=1\",\n",
    "                 \"#SBATCH --mem=350\",\n",
    "                 \"#SBATCH -c 1\",\n",
    "                 \"#SBATCH --mail-type=FAIL # notifications for job failure only\",\n",
    "                 \"#SBATCH --mail-user=ebeam@stanford.edu\\n\",\n",
    "                 \"module load python/2.7.13 biology fsl/5.0.10\",\n",
    "                 \"srun python preproc_{}.py\".format(pmid)]\n",
    "        for line in lines:\n",
    "            bashfile.write(line + \"\\n\")\n",
    "        bashfile.close()\n",
    "        \n",
    "        # Copy over preprocessing and wrap scripts\n",
    "        copyfile(\"neurosynth/neurosynth_preproc_coords/preproc_coords.py\", \"neurosynth/neurosynth_preproc_coords/{}mm/preproc_coords.py\".format(sigma))\n",
    "        copyfile(\"neurosynth/neurosynth_preproc_coords/wrap.sh\", \"neurosynth/neurosynth_preproc_coords/{}mm/wrap.sh\".format(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = chunkify(list(set(ns[\"id\"])), 150)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    lines = [\"#!/bin/sh\", \n",
    "             'IDS=\"{}\"'.format(\" \".join([str(id) for id in chunk])),\n",
    "            \"for ID in $IDS; do\",\n",
    "            \"if [ ! -f '/scratch/PI/aetkin/ebeam/cogneuro/neurosynth/coordinates/5mm/${ID}.txt' ]\", \n",
    "            \"then\", \n",
    "            \"echo `sbatch preproc_${ID}.sbatch`\", \n",
    "            \"sleep 1\", \n",
    "            \"fi\", \n",
    "            \"done\"]\n",
    "    file = open(\"neurosynth/neurosynth_preproc_coords/5mm/wrap_{}.sh\".format(i), \"w+\")\n",
    "    for line in lines:\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata with coordinates in unknown space removed\n",
    "ac_old = pd.read_csv(\"ace/ace_180711.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ac_old[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata with coordinates in unknown space removed\n",
    "ac_new = pd.read_csv(\"ace/ace_180804.csv\", header=0, index_col=None)\n",
    "len(list(set(list(ac_new[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac_new = ac_new[~(ac_new[\"id\"].isin(list(ac_old[\"id\"])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac_new = ac_new[~(ac_new[\"space\"] == \"UNKNOWN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(list(ac_new[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac = ac_old.append(ac_new)\n",
    "ac.to_csv(\"ace_180805.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(list(ac[\"id\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs and HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt download with ruby script\n",
    "for pmid in list(set(ac_new[\"id\"])):\n",
    "    try:\n",
    "        cogneuro_file = \"../texts/pdf/{}.pdf\".format(int(pmid))\n",
    "        pubmed_file = \"../../pubmed/vetted/{}.pdf\".format(int(pmid))\n",
    "        if not os.path.isfile(cogneuro_file):\n",
    "            if os.path.isfile(pubmed_file):\n",
    "                shutil.move(pubmed_file, \"pdf/{}.pdf\".format(pmid))\n",
    "            else:\n",
    "                comm = \"ruby /Users/ehbeam/Dropbox/Stanford/Research/Projects/Psychiatlas/scripts/borrowed/Pubmed-Batch-Download-master/pubmedid2pdf.rb {}\".format(int(pmid))\n",
    "                args = shlex.split(comm)\n",
    "                proc = subprocess.call(args)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download PDFs of PloS One articles\n",
    "http = httplib2.Http()\n",
    "downloaded = [int(file.replace(\".pdf\",\"\")) for file in os.listdir(\"../texts/pdf\") if not file.startswith(\".\")]\n",
    "for i, row in ac_new.iterrows():\n",
    "    if row[\"journal\"] == \"PloS one\" and row[\"id\"] not in downloaded:\n",
    "        pdf_url = \"http://journals.plos.org/plosone/article/file?id={}&type=printable\".format(row[\"doi\"])\n",
    "        pdf_file = \"pdf/{}.pdf\".format(row[\"id\"])\n",
    "        comm = \"wget -O {} {}\".format(pdf_file, pdf_url)\n",
    "        args = shlex.split(comm)\n",
    "        proc = subprocess.Popen(args)\n",
    "        sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save PubMed links that redirect to publisher site for PDF download \n",
    "downloaded = [int(file.replace(\".pdf\", \"\")) for file in os.listdir(\"../texts/pdf\") if not file.startswith(\".\")]\n",
    "missing = [pmid for pmid in list(set(ac[\"id\"])) if pmid not in downloaded]\n",
    "missing_url = [\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(pmid) for pmid in missing]\n",
    "missing_df = pd.DataFrame({\"URL\": missing_url, \"PMID\": missing})\n",
    "missing_df.to_csv(path_or_buf=\"../texts/download/failed_pdfs_ace.csv\", index=None, columns=[\"URL\",\"PMID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get list of PMIDs for HTML download\n",
    "journal = \"Journal of neuroimaging\"\n",
    "min_pmid = 0\n",
    "query = \"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=({}[Journal]+journal+article[pt]+fmri)&retmax=15000\".format(journal.replace(\" \", \"+\"))\n",
    "req = requests.get(query, timeout=5.0).text\n",
    "soup = BeautifulSoup(req, \"lxml\")\n",
    "ids = [t.string for t in soup.find_all('id')]\n",
    "downloaded = [file.replace(\".html\", \"\") for file in os.listdir(\"ace/ACE/articles/html/{}\".format(journal))]\n",
    "to_download = [id for id in ids if id not in downloaded and int(id) > min_pmid]\n",
    "print(\"Number to download: {}\".format(len(to_download)))\n",
    "i = 1\n",
    "for pmid in to_download:\n",
    "    print(\"{} {} http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(i, pmid, pmid))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add column for MNI coordinates\n",
    "ac = pd.read_csv(\"ace/ace_180805.csv\", header=0, index_col=None)\n",
    "ac[\"mni_coord\"] = ac[\"x\"].map(str) + \",\" + ac[\"y\"].map(str) + \",\" + ac[\"z\"].map(str)\n",
    "ac.loc[ac.space != \"MNI\", [\"mni_coord\"]] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to convert Talairach coordinates to MNI space\n",
    "# Adapted from https://github.com/neurosynth/neurosynth/blob/master/neurosynth/base/transformations.py\n",
    "\n",
    "def transform(foci, mat):\n",
    "    \"\"\" Convert coordinates from one space to another using provided\n",
    "    transformation matrix. \"\"\"\n",
    "    t = linalg.pinv(mat)\n",
    "    foci = np.hstack((foci, np.ones((foci.shape[0], 1))))\n",
    "    return np.dot(foci, t)[:, 0:3]\n",
    "\n",
    "def t88_to_mni():\n",
    "    \"\"\" Convert Talairach to MNI coordinates using the Lancaster transform.\n",
    "    Adapted from BrainMap scripts; see http://brainmap.org/icbm2tal/\n",
    "    Details are described in Lancaster et al. (2007)\n",
    "    (http://brainmap.org/new/pubs/LancasterHBM07.pdf). \"\"\"\n",
    "    return np.array([[0.9254, 0.0024, -0.0118, -1.0207],\n",
    "                     [-0.0048, 0.9316, -0.0871, -1.7667],\n",
    "                     [0.0152, 0.0883, 0.8924, 4.0926],\n",
    "                     [0.0, 0.0, 0.0, 1.0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>space</th>\n",
       "      <th>peak_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_num</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>mni_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>10585521</td>\n",
       "      <td>10.1016/S0010-0277(99)00060-8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>20094</td>\n",
       "      <td>1337</td>\n",
       "      <td>2</td>\n",
       "      <td>Temporal cortex activation during speech recog...</td>\n",
       "      <td>Sato H, Takeuchi T, Sakai KL</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cognition</td>\n",
       "      <td>17.442356860158288,20.505386127425055,14.37881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>10585521</td>\n",
       "      <td>10.1016/S0010-0277(99)00060-8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>20095</td>\n",
       "      <td>1337</td>\n",
       "      <td>2</td>\n",
       "      <td>Temporal cortex activation during speech recog...</td>\n",
       "      <td>Sato H, Takeuchi T, Sakai KL</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cognition</td>\n",
       "      <td>17.442356860158288,20.505386127425055,14.37881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>10585521</td>\n",
       "      <td>10.1016/S0010-0277(99)00060-8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>20096</td>\n",
       "      <td>1337</td>\n",
       "      <td>2</td>\n",
       "      <td>Temporal cortex activation during speech recog...</td>\n",
       "      <td>Sato H, Takeuchi T, Sakai KL</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cognition</td>\n",
       "      <td>17.443944140124717,23.799948025882983,15.17337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>10666562</td>\n",
       "      <td>10.1016/S0926-6410(99)00029-4</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>20256</td>\n",
       "      <td>1348</td>\n",
       "      <td>1</td>\n",
       "      <td>Prefrontal cortex activation in task switching...</td>\n",
       "      <td>Dove A, Pollmann S, Schubert T, Wiggins CJ, vo...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Brain research. Cognitive brain research</td>\n",
       "      <td>-46.00411768534114,10.45071901107778,36.624679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>10666562</td>\n",
       "      <td>10.1016/S0926-6410(99)00029-4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>TAL</td>\n",
       "      <td>20257</td>\n",
       "      <td>1348</td>\n",
       "      <td>1</td>\n",
       "      <td>Prefrontal cortex activation in task switching...</td>\n",
       "      <td>Dove A, Pollmann S, Schubert T, Wiggins CJ, vo...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Brain research. Cognitive brain research</td>\n",
       "      <td>44.720313185949635,13.85767378403707,33.621715...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                            doi     x     y     z space  \\\n",
       "79974  10585521  10.1016/S0010-0277(99)00060-8  15.0  16.0  19.0   TAL   \n",
       "79975  10585521  10.1016/S0010-0277(99)00060-8  15.0  16.0  19.0   TAL   \n",
       "79976  10585521  10.1016/S0010-0277(99)00060-8  15.0  19.0  20.0   TAL   \n",
       "79977  10666562  10.1016/S0926-6410(99)00029-4 -44.0   5.0  37.0   TAL   \n",
       "79978  10666562  10.1016/S0926-6410(99)00029-4  40.0   8.0  36.0   TAL   \n",
       "\n",
       "       peak_id  table_id table_num  \\\n",
       "79974    20094      1337         2   \n",
       "79975    20095      1337         2   \n",
       "79976    20096      1337         2   \n",
       "79977    20256      1348         1   \n",
       "79978    20257      1348         1   \n",
       "\n",
       "                                                   title  \\\n",
       "79974  Temporal cortex activation during speech recog...   \n",
       "79975  Temporal cortex activation during speech recog...   \n",
       "79976  Temporal cortex activation during speech recog...   \n",
       "79977  Prefrontal cortex activation in task switching...   \n",
       "79978  Prefrontal cortex activation in task switching...   \n",
       "\n",
       "                                                 authors  year  \\\n",
       "79974                       Sato H, Takeuchi T, Sakai KL  1999   \n",
       "79975                       Sato H, Takeuchi T, Sakai KL  1999   \n",
       "79976                       Sato H, Takeuchi T, Sakai KL  1999   \n",
       "79977  Dove A, Pollmann S, Schubert T, Wiggins CJ, vo...  2000   \n",
       "79978  Dove A, Pollmann S, Schubert T, Wiggins CJ, vo...  2000   \n",
       "\n",
       "                                        journal  \\\n",
       "79974                                 Cognition   \n",
       "79975                                 Cognition   \n",
       "79976                                 Cognition   \n",
       "79977  Brain research. Cognitive brain research   \n",
       "79978  Brain research. Cognitive brain research   \n",
       "\n",
       "                                               mni_coord  \n",
       "79974  17.442356860158288,20.505386127425055,14.37881...  \n",
       "79975  17.442356860158288,20.505386127425055,14.37881...  \n",
       "79976  17.443944140124717,23.799948025882983,15.17337...  \n",
       "79977  -46.00411768534114,10.45071901107778,36.624679...  \n",
       "79978  44.720313185949635,13.85767378403707,33.621715...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Talairach coordinates to MNI space by Lancaster transform\n",
    "tal2mni = transform(ac[['x', 'y', 'z']].values, t88_to_mni())\n",
    "tal2mni_str = []\n",
    "for row in tal2mni:\n",
    "    tal2mni_str.append(str(row[0]) + \",\" + str(row[1]) + \",\" + str(row[2]))\n",
    "tal2mni_ser = pd.Series(tal2mni_str)\n",
    "ac.loc[ac[\"space\"] == \"TAL\", \"mni_coord\"] = tal2mni_ser\n",
    "ac[ac[\"space\"] == \"TAL\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117264, 14)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop coordinates in an unknown space\n",
    "ac = ac[ac[\"space\"] != \"UNKNOWN\"]\n",
    "ac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save ACE metadata with transformed coordinates\n",
    "ac.to_csv(path_or_buf=\"ace/ace_180805.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload data from file\n",
    "ac = pd.read_csv(\"ace/ace_180805.csv\", header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3868"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(list(ac[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write scripts to preprocess coordinates\n",
    "long = []\n",
    "for sigma in [0, 5]:\n",
    "    \n",
    "    # Create directory for current smoothing sigma\n",
    "    if not os.path.exists(\"ace/ace_preproc_coords/{}mm\".format(sigma)):\n",
    "        os.makedirs(\"ace/ace_preproc_coords/{}mm\".format(sigma))\n",
    "    if not os.path.exists(\"ace/ace_preproc_coords/{}mm/logs\".format(sigma)):\n",
    "        os.makedirs(\"ace/ace_preproc_coords/{}mm/logs\".format(sigma))\n",
    "    \n",
    "    for pmid in list(set(list(ac[\"id\"]))):\n",
    "\n",
    "        # Format preprocessing command\n",
    "        coords = list(ac[ac[\"id\"] == pmid][\"mni_coord\"])\n",
    "        comm = \"pc.run_preproc(path, {}, {}, smoothing_sigma={}, mask_path=mask_path)\".format(coords, pmid, sigma)\n",
    "        \n",
    "        # Write python script with command for executing preprocessing\n",
    "        pyfile = open(\"ace/ace_preproc_coords/{}mm/preproc_{}.py\".format(sigma, pmid), \"w+\")\n",
    "        pyfile.write(\"#!/bin/python\\n\\nimport preproc_coords as pc\\n\\npath = '/scratch/PI/aetkin/ebeam/cogneuro/ace'\\nmask_path = '/scratch/PI/aetkin/ebeam/cogneuro/masks'\\n\\n{}\".format(comm))\n",
    "        pyfile.close()\n",
    "        \n",
    "        # Scale script duration to number of coordinates\n",
    "        mins = 5*len(set(coords))\n",
    "        qos = \"#\"\n",
    "        partition = \"normal\"\n",
    "        if mins > 600:\n",
    "            qos = \"\"\n",
    "            partition = \"normal\"\n",
    "            long.append(pmid)\n",
    "        \n",
    "        # Write bash script for slurm submission\n",
    "        bashfile = open(\"ace/ace_preproc_coords/{}mm/preproc_{}.sbatch\".format(sigma, pmid), \"w+\")\n",
    "        lines = [\"#!/bin/bash\\n\",\n",
    "                 \"#SBATCH --job-name={}\".format(pmid),\n",
    "                 \"#SBATCH --output=logs/{}.%j.out\".format(pmid),\n",
    "                 \"#SBATCH --error=logs/{}.%j.err\".format(pmid),\n",
    "                 \"#SBATCH --time={}\".format(str(timedelta(minutes=mins))),\n",
    "                 \"#SBATCH -p {}\".format(partition),\n",
    "                 \"{}#SBATCH --qos=long\".format(qos),\n",
    "                 \"#SBATCH --nodes=1\",\n",
    "                 \"#SBATCH --mem=350\",\n",
    "                 \"#SBATCH -c 1\",\n",
    "                 \"#SBATCH --mail-type=FAIL # notifications for job failure only\",\n",
    "                 \"#SBATCH --mail-user=ebeam@stanford.edu\\n\",\n",
    "                 \"module load python/2.7.13 biology fsl/5.0.10\",\n",
    "                 \"srun python preproc_{}.py\".format(pmid)]\n",
    "        for line in lines:\n",
    "            bashfile.write(line + \"\\n\")\n",
    "        bashfile.close()\n",
    "        \n",
    "    # Copy over preprocessing and wrap scripts\n",
    "    copyfile(\"ace/ace_preproc_coords/preproc_coords.py\", \"ace/ace_preproc_coords/{}mm/preproc_coords.py\".format(sigma))\n",
    "    copyfile(\"ace/ace_preproc_coords/wrap.sh\", \"ace/ace_preproc_coords/{}mm/wrap.sh\".format(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04446742502585315"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long) / len(list(set(list(ac[\"id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to split list into list of n-sized chunks\n",
    "def chunkify(l, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(l), n):\n",
    "        chunks.append(l[i:i + n])\n",
    "    leftover = len(l)-(len(l)*n)\n",
    "    chunks.append(l[-leftover:])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = chunkify(list(set(list(ac[\"id\"]))), 100)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    lines = [\"#!/bin/sh\", \n",
    "             'IDS=\"{}\"'.format(\" \".join([str(id) for id in chunk])),\n",
    "            \"for ID in $IDS; do\",\n",
    "            \"if [ ! -f '/scratch/PI/aetkin/ebeam/cogneuro/ace/coordinates/0mm/${ID}.txt' ]\", \n",
    "            \"then\", \n",
    "            \"echo `sbatch preproc_${ID}.sbatch`\", \n",
    "            \"sleep 1\", \n",
    "            \"fi\",\n",
    "            \"done\"]\n",
    "    file = open(\"ace/ace_preproc_coords/0mm/wrap_{}.sh\".format(i), \"w+\")\n",
    "    for line in lines:\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehbeam/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (10,12,14,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,118,120,122,124,126,128,130,132,134,136,138,140,142,144,146,148,150,152,154,156,158,160,162,164,166,168,170,172,174,176,178,180,182,184,186,188,190,192,194,196,198,200,202,204,206,208,210,212,214,216,218,220,222,224,226,228,230,232,234,236,238,240,242) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Attempt scraping of missing PDFs\n",
    "df_filt = pd.read_csv(\"metadata_filt_180805.csv\", \n",
    "                      index_col=None, header=0, encoding=\"cp858\")\n",
    "for pmid in df_filt[\"PMID\"]:\n",
    "    cogneuro_file = \"../texts/pdf/{}.pdf\".format(int(pmid))\n",
    "    pubmed_file = \"../../pubmed/vetted/{}.pdf\".format(int(pmid))\n",
    "    try:\n",
    "        if not os.path.isfile(cogneuro_file):\n",
    "            if os.path.isfile(pubmed_file):\n",
    "                shutil.move(pubmed_file, \"pdf/{}.pdf\".format(pmid))\n",
    "            else:\n",
    "                comm = \"ruby /Users/ehbeam/Dropbox/Stanford/Research/Projects/Psychiatlas/scripts/borrowed/Pubmed-Batch-Download-master/pubmedid2pdf.rb {}\".format(int(pmid))\n",
    "                args = shlex.split(comm)\n",
    "                proc = subprocess.call(args)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save PubMed links that redirect to publisher site for PDF download \n",
    "downloaded = [int(file.replace(\".pdf\", \"\")) for file in os.listdir(\"../texts/pdf\") if not file.startswith(\".\")]\n",
    "missing = [pmid for pmid in df_filt[\"PMID\"] if pmid not in downloaded]\n",
    "missing_url = [\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id={}&cmd=prlinks&retmode=ref\".format(pmid) for pmid in missing]\n",
    "missing_df = pd.DataFrame({\"URL\": missing_url, \"PMID\": missing})\n",
    "missing_df.to_csv(path_or_buf=\"../texts/download/failed_pdfs_combo.csv\", index=None, columns=[\"URL\",\"PMID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author manuscript XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>MID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17017123</th>\n",
       "      <td>PMC0016XXXXX/PMC1626270.xml</td>\n",
       "      <td>PMC1626270</td>\n",
       "      <td>NIHMS12889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837037</th>\n",
       "      <td>PMC0019XXXXX/PMC1913286.xml</td>\n",
       "      <td>PMC1913286</td>\n",
       "      <td>NIHMS16708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19023455</th>\n",
       "      <td>PMC0021XXXXX/PMC2136438.xml</td>\n",
       "      <td>PMC2136438</td>\n",
       "      <td>NIHMS10936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18769527</th>\n",
       "      <td>PMC0021XXXXX/PMC2185066.xml</td>\n",
       "      <td>PMC2185066</td>\n",
       "      <td>NIHMS31656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17661176</th>\n",
       "      <td>PMC0022XXXXX/PMC2268633.xml</td>\n",
       "      <td>PMC2268633</td>\n",
       "      <td>NIHMS37031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File       PMCID         MID\n",
       "PMID                                                         \n",
       "17017123  PMC0016XXXXX/PMC1626270.xml  PMC1626270  NIHMS12889\n",
       "12837037  PMC0019XXXXX/PMC1913286.xml  PMC1913286  NIHMS16708\n",
       "19023455  PMC0021XXXXX/PMC2136438.xml  PMC2136438  NIHMS10936\n",
       "18769527  PMC0021XXXXX/PMC2185066.xml  PMC2185066  NIHMS31656\n",
       "17661176  PMC0022XXXXX/PMC2268633.xml  PMC2268633  NIHMS37031"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Volumes/Samsung_T5/open_access\"\n",
    "oa = pd.read_csv(\"{}/manuscript/oa_manuscript.csv\".format(path), index_col=\"PMID\", header=0)\n",
    "oa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmids = [int(pmid) for pmid in df[\"PMID\"] if int(pmid) in oa.index]\n",
    "len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_manuscript(raw_file, xml_file, pmid):\n",
    "    soup = BeautifulSoup(open(xml_file, \"r\").read()).article\n",
    "    text = \" \".join(soup.findAll(text=True))\n",
    "    with open(raw_file, \"w+\") as raw:\n",
    "        raw.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added = []\n",
    "for pmid in pmids:\n",
    "    pmc = oa.loc[pmid, \"PMCID\"]\n",
    "    pmc_pre = pmc.replace(\"PMC\", \"PMC00\")\n",
    "    raw_file = \"{}/raw/cogneuro_180805/{}.txt\".format(path, pmid)\n",
    "    if not os.path.isfile(raw_file):\n",
    "        if pmc[3] in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "            pmc_pre = pmc.replace(\"PMC\", \"PMC00\")[:7]\n",
    "            xml_file = \"{}/manuscript/{}XXXXXX.xml/{}/{}.xml\".format(path, pmc_pre[:-1], pmc_pre + \"XXXXX\", pmc)\n",
    "            extract_manuscript(raw_file, xml_file, pmid)\n",
    "            added.append(pmid)\n",
    "        elif pmc[3] == \"6\":\n",
    "            xml_file = \"{}/manuscript/PMC0060XXXXX/{}.xml\".format(path, pmc)\n",
    "            extract_manuscript(raw_file, xml_file, pmid)\n",
    "            added.append(pmid)\n",
    "len(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open access XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison [arraysetops.py:472]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Article Citation</th>\n",
       "      <th>Accession ID</th>\n",
       "      <th>Last Updated (YYYY-MM-DD HH:MM:SS)</th>\n",
       "      <th>License</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11250746.0</th>\n",
       "      <td>oa_package/08/e0/PMC13900.tar.gz</td>\n",
       "      <td>Breast Cancer Res. 2001 Nov 2; 3(1):55-60</td>\n",
       "      <td>PMC13900</td>\n",
       "      <td>2017-04-26 12:15:50</td>\n",
       "      <td>NO-CC CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250747.0</th>\n",
       "      <td>oa_package/b0/ac/PMC13901.tar.gz</td>\n",
       "      <td>Breast Cancer Res. 2001 Nov 9; 3(1):61-65</td>\n",
       "      <td>PMC13901</td>\n",
       "      <td>2016-01-20 10:58:46</td>\n",
       "      <td>NO-CC CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250748.0</th>\n",
       "      <td>oa_package/f7/98/PMC13902.tar.gz</td>\n",
       "      <td>Breast Cancer Res. 2001 Nov 8; 3(1):66-75</td>\n",
       "      <td>PMC13902</td>\n",
       "      <td>2006-02-02 19:37:52</td>\n",
       "      <td>NO-CC CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11056684.0</th>\n",
       "      <td>oa_package/9c/7f/PMC13911.tar.gz</td>\n",
       "      <td>Breast Cancer Res. 2000 Nov 16; 2(1):59-63</td>\n",
       "      <td>PMC13911</td>\n",
       "      <td>2013-03-17 14:00:52</td>\n",
       "      <td>NO-CC CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11400682.0</th>\n",
       "      <td>oa_package/c6/fb/PMC13912.tar.gz</td>\n",
       "      <td>Breast Cancer Res. 2000 Dec 6; 2(1):64-72</td>\n",
       "      <td>PMC13912</td>\n",
       "      <td>2013-03-17 14:00:52</td>\n",
       "      <td>NO-CC CODE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        File  \\\n",
       "PMID                                           \n",
       "11250746.0  oa_package/08/e0/PMC13900.tar.gz   \n",
       "11250747.0  oa_package/b0/ac/PMC13901.tar.gz   \n",
       "11250748.0  oa_package/f7/98/PMC13902.tar.gz   \n",
       "11056684.0  oa_package/9c/7f/PMC13911.tar.gz   \n",
       "11400682.0  oa_package/c6/fb/PMC13912.tar.gz   \n",
       "\n",
       "                                      Article Citation Accession ID  \\\n",
       "PMID                                                                  \n",
       "11250746.0   Breast Cancer Res. 2001 Nov 2; 3(1):55-60     PMC13900   \n",
       "11250747.0   Breast Cancer Res. 2001 Nov 9; 3(1):61-65     PMC13901   \n",
       "11250748.0   Breast Cancer Res. 2001 Nov 8; 3(1):66-75     PMC13902   \n",
       "11056684.0  Breast Cancer Res. 2000 Nov 16; 2(1):59-63     PMC13911   \n",
       "11400682.0   Breast Cancer Res. 2000 Dec 6; 2(1):64-72     PMC13912   \n",
       "\n",
       "           Last Updated (YYYY-MM-DD HH:MM:SS)     License  \n",
       "PMID                                                       \n",
       "11250746.0                2017-04-26 12:15:50  NO-CC CODE  \n",
       "11250747.0                2016-01-20 10:58:46  NO-CC CODE  \n",
       "11250748.0                2006-02-02 19:37:52  NO-CC CODE  \n",
       "11056684.0                2013-03-17 14:00:52  NO-CC CODE  \n",
       "11400682.0                2013-03-17 14:00:52  NO-CC CODE  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oa = pd.read_csv(\"../../pubmed/open_access/oa_file_list.csv\", index_col=\"PMID\", header=0)\n",
    "oa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmids = [pmid for pmid in df[\"PMID\"] if float(pmid) in oa.index]\n",
    "len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "path = \"/Volumes/Samsung_T5/open_access\"\n",
    "for pmid in pmids:\n",
    "    tar_file = \"{}/oa_package/{}.tar.gz\".format(path, pmid)\n",
    "    pmid_dir = \"{}/oa_package/{}\".format(path, pmid)\n",
    "    out_file = \"{}/xml/cogneuro_180805/{}.xml\".format(path, pmid)\n",
    "    if not os.path.isfile(tar_file):\n",
    "        tar_url = \"ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/{}\".format(oa.loc[float(pmid),\"File\"])\n",
    "        comm = \"wget -O {} {}\".format(tar_file, tar_url)\n",
    "        args = shlex.split(comm)\n",
    "        proc = subprocess.call(args)\n",
    "        tar = tarfile.open(tar_file)\n",
    "        tar.extractall(path=pmid_dir)\n",
    "        tar.close()\n",
    "    if not os.path.isfile(out_file):\n",
    "        pmcid = oa.loc[float(pmid), \"Accession ID\"]\n",
    "        xml_file = [file for file in os.listdir(\"{}/{}\".format(pmid_dir, pmcid)) if file.endswith(\"xml\")][0]\n",
    "        shutil.copy(\"{}/{}/{}\".format(pmid_dir, pmcid, xml_file), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "path = \"/Volumes/Samsung_T5/open_access\"\n",
    "for pmid in pmids:\n",
    "    xml_file = \"{}/xml/cogneuro_180805/{}.xml\".format(path, pmid)\n",
    "    raw_file = \"{}/raw/cogneuro_180805/{}.txt\".format(path, pmid)\n",
    "    if os.path.isfile(xml_file):\n",
    "        soup = BeautifulSoup(open(xml_file, \"r\").read()).article\n",
    "        text = \" \".join(soup.findAll(text=True))\n",
    "        with open(raw_file, \"w+\") as raw:\n",
    "            raw.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12135962, 17803835, 18209203, 18822455, 21958514]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify duplicates\n",
    "from collections import Counter\n",
    "duplicates = [k for k, v in Counter(df[\"PMID\"]).items() if v > 1]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>DOI</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>AUTHORS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>PAGES</th>\n",
       "      <th>...</th>\n",
       "      <th>ABSTRACT_URL</th>\n",
       "      <th>NUM_COORDINATES</th>\n",
       "      <th>MNI_COORDS</th>\n",
       "      <th>NUM_SUBJECTS</th>\n",
       "      <th>BRAINMAP_ID</th>\n",
       "      <th>BEHAVIORAL_DOMAIN</th>\n",
       "      <th>EXPERIMENT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>COORDS_AVAILABLE</th>\n",
       "      <th>TEXTS_AVAILABLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>12135962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berthoz S, 2002</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Berthoz S|Armony J L|Blair R J R|Dolan R J</td>\n",
       "      <td>2002</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Brain</td>\n",
       "      <td>An fMRI study of intentional and unintentional...</td>\n",
       "      <td>1696-1708</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18040043.0</td>\n",
       "      <td>['Emotion.Negative.Anxiety', 'Emotion.Negative...</td>\n",
       "      <td>['Violation of social norms &gt; Normal behaviour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>12135962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berthoz S, 2002</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Berthoz S|Armony J L|Blair R J R|Dolan R J</td>\n",
       "      <td>2002</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Brain</td>\n",
       "      <td>An fMRI study of intentional and unintentional...</td>\n",
       "      <td>1696-1708</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17110231.0</td>\n",
       "      <td>['Emotion.Negative.Anxiety', 'Emotion.Negative...</td>\n",
       "      <td>['Violation of social norms &gt; Normal behaviour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>17803835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lindauer R J, 2008</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Lindauer R J|Booij J|Habraken J B|van Meijel E...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Psychological Medicine</td>\n",
       "      <td>Effects of psychotherapy on regional cerebral ...</td>\n",
       "      <td>543-554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16120224.0</td>\n",
       "      <td>['Emotion.Other,Cognition.Memory.Explicit', 'E...</td>\n",
       "      <td>['PTSD &gt; Traumatized Controls, Trauma vs. Base...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>17803835</td>\n",
       "      <td>10.1017/S0033291707001432</td>\n",
       "      <td>Liu L, 2012</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Liu L|Wang W|You W|Li Y|Awati N|Zhao X|Booth J...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Neuropsychologia</td>\n",
       "      <td>Similar alterations in brain function for phon...</td>\n",
       "      <td>2224-2232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17010014.0</td>\n",
       "      <td>['Cognition.Attention,Cognition.Language.Phono...</td>\n",
       "      <td>['Control &gt; Reading Disabled, All tasks', 'Sem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>18209203</td>\n",
       "      <td>10.1212/01.wnl.0000287115.85956.87</td>\n",
       "      <td>Raboyeau G, 2008</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Raboyeau G|De Boissezon X|Marie N|Balduyck S|P...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Right hemisphere activation in recovery from A...</td>\n",
       "      <td>290-298</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-8,-90,6;8,6,28;6,-20,-14;-42,2,22;-38,-12,58;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11010022.0</td>\n",
       "      <td>['Action.Execution.Speech,Cognition.Language.S...</td>\n",
       "      <td>['Naming - Rest, After - Before Computer Assis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>18209203</td>\n",
       "      <td>10.1212/01.wnl.0000287115.85956.87</td>\n",
       "      <td>Bookheimer S Y, 1995</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Bookheimer S Y|Zeffiro T A|Blaxton T A|Gaillar...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Sep</td>\n",
       "      <td>Human Brain Mapping</td>\n",
       "      <td>Regional cerebral blood flow during object nam...</td>\n",
       "      <td>93-106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-8,-90,6;8,6,28;6,-20,-14;-42,2,22;-38,-12,58;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30241.0</td>\n",
       "      <td>['Cognition.Language.Orthography', 'Cognition....</td>\n",
       "      <td>['Read Words Silently - Words Control', 'Read ...</td>\n",
       "      <td>Subjects underwent 6 conditions in which they ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>18822455</td>\n",
       "      <td>10.1016/j.bandl.2008.07.003</td>\n",
       "      <td>De Nil L F, 2017</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>De Nil L F|Beal D S|Lafaille S J|Kroll R M|Cra...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Brain and Language</td>\n",
       "      <td>The effects of simulated stuttering and prolon...</td>\n",
       "      <td>114-123</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-58,-20,4;-54,-16,2;-46,-2,-10;-6,-34,-8;0,16,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17040087.0</td>\n",
       "      <td>['Perception.Audition', 'Perception.Audition',...</td>\n",
       "      <td>['Listen - Baseline, Controls', 'Listen - Base...</td>\n",
       "      <td>PURPOSE: Functional magnetic resonance imaging...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>18822455</td>\n",
       "      <td>10.1016/j.bandl.2008.07.003</td>\n",
       "      <td>De Nil L F, 2008</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>De Nil L F|Beal D S|Lafaille S J|Kroll R M|Cra...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Brain and Language</td>\n",
       "      <td>The effects of simulated stuttering and prolon...</td>\n",
       "      <td>114-123</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-58,-20,4;-54,-16,2;-46,-2,-10;-6,-34,-8;0,16,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13010002.0</td>\n",
       "      <td>['Perception.Audition,Cognition.Language.Speec...</td>\n",
       "      <td>['Listen minus Baseline, Healthy Controls', 'L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>21958514</td>\n",
       "      <td>10.1016/j.pscychresns.2011.05.001</td>\n",
       "      <td>Barros-Loscertales A, 2011</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Barros-Loscertales A|Bustamante JC|Ventura-Cam...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Psychiatry Research</td>\n",
       "      <td>Lower activation in the right frontoparietal n...</td>\n",
       "      <td>111-118</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17110230.0</td>\n",
       "      <td>['Cognition.Attention', 'Cognition.Attention',...</td>\n",
       "      <td>['Counting stroop task &gt; Control, Healthy Cont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>21958514</td>\n",
       "      <td>10.1016/j.pscychresns.2011.05.001</td>\n",
       "      <td>Barros-Loscertales A, 2011</td>\n",
       "      <td>BrainMap</td>\n",
       "      <td>Barros-Loscertales A|Bustamante JC|Ventura-Cam...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Psychiatry Research: Neuroimaging</td>\n",
       "      <td>Lower activation in the right frontoparietal n...</td>\n",
       "      <td>111-118</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14050043.0</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>['Stroop &gt; Control, Healthy Controls', 'Stroop...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PMID                                 DOI  \\\n",
       "753   12135962                                 NaN   \n",
       "754   12135962                                 NaN   \n",
       "1996  17803835                                 NaN   \n",
       "1997  17803835           10.1017/S0033291707001432   \n",
       "2103  18209203  10.1212/01.wnl.0000287115.85956.87   \n",
       "2104  18209203  10.1212/01.wnl.0000287115.85956.87   \n",
       "2279  18822455         10.1016/j.bandl.2008.07.003   \n",
       "2280  18822455         10.1016/j.bandl.2008.07.003   \n",
       "2823  21958514   10.1016/j.pscychresns.2011.05.001   \n",
       "2824  21958514   10.1016/j.pscychresns.2011.05.001   \n",
       "\n",
       "                             KEY    SOURCE  \\\n",
       "753              Berthoz S, 2002  BrainMap   \n",
       "754              Berthoz S, 2002  BrainMap   \n",
       "1996          Lindauer R J, 2008  BrainMap   \n",
       "1997                 Liu L, 2012  BrainMap   \n",
       "2103            Raboyeau G, 2008  BrainMap   \n",
       "2104        Bookheimer S Y, 1995  BrainMap   \n",
       "2279            De Nil L F, 2017  BrainMap   \n",
       "2280            De Nil L F, 2008  BrainMap   \n",
       "2823  Barros-Loscertales A, 2011  BrainMap   \n",
       "2824  Barros-Loscertales A, 2011  BrainMap   \n",
       "\n",
       "                                                AUTHORS  YEAR MONTH  \\\n",
       "753          Berthoz S|Armony J L|Blair R J R|Dolan R J  2002   Jan   \n",
       "754          Berthoz S|Armony J L|Blair R J R|Dolan R J  2002   Jan   \n",
       "1996  Lindauer R J|Booij J|Habraken J B|van Meijel E...  2008   Apr   \n",
       "1997  Liu L|Wang W|You W|Li Y|Awati N|Zhao X|Booth J...  2012   Jun   \n",
       "2103  Raboyeau G|De Boissezon X|Marie N|Balduyck S|P...  2008   Jan   \n",
       "2104  Bookheimer S Y|Zeffiro T A|Blaxton T A|Gaillar...  1995   Sep   \n",
       "2279  De Nil L F|Beal D S|Lafaille S J|Kroll R M|Cra...  2017   Jan   \n",
       "2280  De Nil L F|Beal D S|Lafaille S J|Kroll R M|Cra...  2008   Nov   \n",
       "2823  Barros-Loscertales A|Bustamante JC|Ventura-Cam...  2011   Nov   \n",
       "2824  Barros-Loscertales A|Bustamante JC|Ventura-Cam...  2011   Nov   \n",
       "\n",
       "                                JOURNAL  \\\n",
       "753                               Brain   \n",
       "754                               Brain   \n",
       "1996             Psychological Medicine   \n",
       "1997                   Neuropsychologia   \n",
       "2103                          Neurology   \n",
       "2104                Human Brain Mapping   \n",
       "2279                 Brain and Language   \n",
       "2280                 Brain and Language   \n",
       "2823                Psychiatry Research   \n",
       "2824  Psychiatry Research: Neuroimaging   \n",
       "\n",
       "                                                  TITLE      PAGES  \\\n",
       "753   An fMRI study of intentional and unintentional...  1696-1708   \n",
       "754   An fMRI study of intentional and unintentional...  1696-1708   \n",
       "1996  Effects of psychotherapy on regional cerebral ...    543-554   \n",
       "1997  Similar alterations in brain function for phon...  2224-2232   \n",
       "2103  Right hemisphere activation in recovery from A...    290-298   \n",
       "2104  Regional cerebral blood flow during object nam...     93-106   \n",
       "2279  The effects of simulated stuttering and prolon...    114-123   \n",
       "2280  The effects of simulated stuttering and prolon...    114-123   \n",
       "2823  Lower activation in the right frontoparietal n...    111-118   \n",
       "2824  Lower activation in the right frontoparietal n...    111-118   \n",
       "\n",
       "           ...                                              ABSTRACT_URL  \\\n",
       "753        ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "754        ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "1996       ...                                                       NaN   \n",
       "1997       ...                                                       NaN   \n",
       "2103       ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "2104       ...                                                       NaN   \n",
       "2279       ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "2280       ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "2823       ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "2824       ...         http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...   \n",
       "\n",
       "     NUM_COORDINATES                                         MNI_COORDS  \\\n",
       "753             64.0                                                NaN   \n",
       "754             64.0                                                NaN   \n",
       "1996             7.0                                                NaN   \n",
       "1997             6.0                                                NaN   \n",
       "2103            25.0  -8,-90,6;8,6,28;6,-20,-14;-42,2,22;-38,-12,58;...   \n",
       "2104           133.0  -8,-90,6;8,6,28;6,-20,-14;-42,2,22;-38,-12,58;...   \n",
       "2279            70.0  -58,-20,4;-54,-16,2;-46,-2,-10;-6,-34,-8;0,16,...   \n",
       "2280            70.0  -58,-20,4;-54,-16,2;-46,-2,-10;-6,-34,-8;0,16,...   \n",
       "2823            50.0                                                NaN   \n",
       "2824            22.0                                                NaN   \n",
       "\n",
       "     NUM_SUBJECTS  BRAINMAP_ID  \\\n",
       "753           NaN   18040043.0   \n",
       "754           NaN   17110231.0   \n",
       "1996          NaN   16120224.0   \n",
       "1997          NaN   17010014.0   \n",
       "2103          NaN   11010022.0   \n",
       "2104          NaN      30241.0   \n",
       "2279          NaN   17040087.0   \n",
       "2280          NaN   13010002.0   \n",
       "2823          NaN   17110230.0   \n",
       "2824          NaN   14050043.0   \n",
       "\n",
       "                                      BEHAVIORAL_DOMAIN  \\\n",
       "753   ['Emotion.Negative.Anxiety', 'Emotion.Negative...   \n",
       "754   ['Emotion.Negative.Anxiety', 'Emotion.Negative...   \n",
       "1996  ['Emotion.Other,Cognition.Memory.Explicit', 'E...   \n",
       "1997  ['Cognition.Attention,Cognition.Language.Phono...   \n",
       "2103  ['Action.Execution.Speech,Cognition.Language.S...   \n",
       "2104  ['Cognition.Language.Orthography', 'Cognition....   \n",
       "2279  ['Perception.Audition', 'Perception.Audition',...   \n",
       "2280  ['Perception.Audition,Cognition.Language.Speec...   \n",
       "2823  ['Cognition.Attention', 'Cognition.Attention',...   \n",
       "2824                                         [nan, nan]   \n",
       "\n",
       "                                             EXPERIMENT  \\\n",
       "753   ['Violation of social norms > Normal behaviour...   \n",
       "754   ['Violation of social norms > Normal behaviour...   \n",
       "1996  ['PTSD > Traumatized Controls, Trauma vs. Base...   \n",
       "1997  ['Control > Reading Disabled, All tasks', 'Sem...   \n",
       "2103  ['Naming - Rest, After - Before Computer Assis...   \n",
       "2104  ['Read Words Silently - Words Control', 'Read ...   \n",
       "2279  ['Listen - Baseline, Controls', 'Listen - Base...   \n",
       "2280  ['Listen minus Baseline, Healthy Controls', 'L...   \n",
       "2823  ['Counting stroop task > Control, Healthy Cont...   \n",
       "2824  ['Stroop > Control, Healthy Controls', 'Stroop...   \n",
       "\n",
       "                                            DESCRIPTION COORDS_AVAILABLE  \\\n",
       "753                                                 NaN                1   \n",
       "754                                                 NaN                1   \n",
       "1996                                                NaN                1   \n",
       "1997                                                NaN                1   \n",
       "2103                                                NaN                1   \n",
       "2104  Subjects underwent 6 conditions in which they ...                1   \n",
       "2279  PURPOSE: Functional magnetic resonance imaging...                1   \n",
       "2280                                                NaN                1   \n",
       "2823                                                NaN                1   \n",
       "2824                                                NaN                1   \n",
       "\n",
       "      TEXTS_AVAILABLE  \n",
       "753                 1  \n",
       "754                 1  \n",
       "1996                1  \n",
       "1997                1  \n",
       "2103                1  \n",
       "2104                1  \n",
       "2279                1  \n",
       "2280                1  \n",
       "2823                1  \n",
       "2824                1  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"PMID\"].isin(duplicates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"metadata_filt_180809.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy over preprocessed texts for studies with coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadata_filt_180805.csv\", index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8896772\n",
      "19093617\n"
     ]
    }
   ],
   "source": [
    "for pmid in df[\"PMID\"]:\n",
    "    preproc_file = \"../../synonyms/corpus/{}.txt\".format(pmid)\n",
    "    if not os.path.isfile(preproc_file):\n",
    "        print(pmid)\n",
    "    else:\n",
    "        shutil.copy(preproc_file, \"../texts/rdoc_180716/preproc/{}.txt\".format(pmid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload dataframe\n",
    "df = pd.read_csv(\"metadata_filt_180721.csv\", header=0, index_col=None, encoding=\"cp858\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load region labels\n",
    "inlab = open(\"../labels/harvard-oxford_148struct.csv\", \"r\").readlines()[1:]\n",
    "labels_bilateral = sorted(set([line.split(\",\")[2] for line in inlab]))\n",
    "labels_unilateral = sorted(set([line.split(\",\")[2].replace(\"left_\", \"\").replace(\"right_\", \"\") for line in inlab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to reformat atlasquery output labels\n",
    "def gen_label_bilateral(label):\n",
    "    parts_to_replace = [\"_iiv\", \"_v\", \"_vi\", \"_vermis_vi\", \"_crus_i\", \"_vermis_crus_i\", \"_crus_ii\", \"_vermis_crus_ii\", \"_viib\", \"_vermis_viib\", \"_viiia\", \"_vermis_viiia\", \"_viiib\", \"_vermis_viiib\", \"_ix\", \"_vermis_ix\", \"_x\", \"_vermis_x\"]\n",
    "    for part in parts_to_replace:\n",
    "        if label.endswith(part):\n",
    "            label = label.replace(part, \"_cerebellum\")\n",
    "    parts_to_remove = [\"juxtapositional_lobule_cortex_(formerly_\", \")\", \"_(includes_h1_and_h2\"]\n",
    "    for part in parts_to_remove:\n",
    "        label = label.replace(part, \"\")\n",
    "    return label.strip()\n",
    "\n",
    "def gen_label_unilateral(label):\n",
    "    parts_to_replace = [\"_iiv\", \"_v\", \"_vi\", \"_vermis_vi\", \"_crus_i\", \"_vermis_crus_i\", \"_crus_ii\", \"_vermis_crus_ii\", \"_viib\", \"_vermis_viib\", \"_viiia\", \"_vermis_viiia\", \"_viiib\", \"_vermis_viiib\", \"_ix\", \"_vermis_ix\", \"_x\", \"_vermis_x\"]\n",
    "    for part in parts_to_replace:\n",
    "        if label.endswith(part):\n",
    "            label = label.replace(part, \"_cerebellum\")\n",
    "    parts_to_remove = [\"left_\", \"right_\", \"left\", \"right\", \"juxtapositional_lobule_cortex_(formerly_\", \")\", \"_(includes_h1_and_h2\"]\n",
    "    for part in parts_to_remove:\n",
    "        label = label.replace(part, \"\")\n",
    "    return label.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to compute winner-takes-all (WTA) features for document-coordinate matrix (DCM)\n",
    "def wta_dcm(df, featurizer, suffix=\"\", sigma=0):\n",
    "    dcm = {}\n",
    "    for pmid in sorted(list(df[\"PMID\"])):\n",
    "        dcm[pmid] = {\"PMID\": pmid}\n",
    "        lines = open(\"../coordinates/{}mm/{}.txt\".format(sigma, pmid), \"r\").readlines()\n",
    "        hits = []\n",
    "        for line in lines:\n",
    "            if len(line.split()) > 0:\n",
    "                label = gen_label_unilateral(line.split()[0])\n",
    "                if label in labels_unilateral:\n",
    "                    hits.append(label)\n",
    "        for label in labels_unilateral:\n",
    "            dcm[pmid][label] = featurizer(hits, label)\n",
    "    output = \"../coordinates/dcm/unilateral/dcm_{}mm{}.csv\".format(sigma, suffix)\n",
    "    with open(output, \"w+\"):\n",
    "        out = pd.DataFrame(dcm)\n",
    "        out_trans = pd.DataFrame.transpose(out)\n",
    "        out_trans.to_csv(output, index = False, quoting = 1, columns = [\"PMID\"] + labels_unilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute winner-takes all DCMs\n",
    "wta_dcm(df, lambda hits, label: hits.count(label), suffix=\"_wta_count\", sigma=0)\n",
    "wta_dcm(df, lambda hits, label: int(hits.count(label) > 0), suffix=\"_wta_binary\", sigma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute binarized DCM above a probability threshold\n",
    "# Probability is given as a percentage between 0 and 100\n",
    "def prob_dcm(df, prob, sigma=0, atlas=\"unilateral\", labs=[]): \n",
    "    dcm = {}\n",
    "    for pmid in sorted(list(df[\"PMID\"])):\n",
    "        dcm[pmid] = {}\n",
    "        dcm[pmid][\"PMID\"] = pmid\n",
    "        lines = open(\"../coordinates/{}mm/{}.txt\".format(sigma, pmid), \"r\").readlines()\n",
    "        hits = []\n",
    "        for line in lines:\n",
    "            for struct in line.split(\",\"):\n",
    "                if len(struct.split()) == 2:\n",
    "                    label, p = struct.split()\n",
    "                    if float(p) > prob:\n",
    "                        if atlas == \"unilateral\":\n",
    "                            hits += [gen_label_unilateral(label)]\n",
    "                        elif atlas == \"bilateral\":\n",
    "                            hits += [gen_label_bilateral(label)]\n",
    "        for label in labs:\n",
    "            count = hits.count(label)\n",
    "            if count > 0:\n",
    "                dcm[pmid][label] = 1\n",
    "            else:\n",
    "                dcm[pmid][label] = 0\n",
    "    outfile = \"../coordinates/dcm/{}/dcm_{}mm_thres_{}.csv\".format(atlas, sigma, prob)\n",
    "    with open(outfile, \"w+\"):\n",
    "        out = pd.DataFrame(dcm).transpose()\n",
    "        out.to_csv(outfile, index=False, quoting=1, columns=['PMID'] + labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute DTM without smoothing for unilateral atlas\n",
    "prob_dcm(df, 0, sigma=0, atlas=\"unilateral\", labs=labels_unilateral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of studies that failed to map onto any structures at the probability=0 level\n",
    "dcm = pd.read_csv(\"../coordinates/dcm/unilateral/dcm_0mm_thres_0.csv\", index_col=0, header=0)\n",
    "all0 = dcm[(dcm.T == 0).all()].index\n",
    "all0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17186, 19)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop structures with no mapped coordinates from data frame\n",
    "df_filt = df[~df[\"PMID\"].isin(all0)]\n",
    "df_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort the columns\n",
    "columns = [\"PMID\", \"DOI\", \"KEY\", \"SOURCE\", \"AUTHORS\", \"YEAR\", \"MONTH\", \"JOURNAL\", \"TITLE\", \"PAGES\", \"VOLUME\", \"ABSTRACT_URL\", \"NUM_COORDINATES\", \"MNI_COORDS\", \"NUM_SUBJECTS\", \"BRAINMAP_ID\", \"BEHAVIORAL_DOMAIN\", \"EXPERIMENT\", \"DESCRIPTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the filtered data frame\n",
    "df_filt.to_csv(path_or_buf=\"metadata_filt_180721.csv\", index=None, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recompute DCMs with filtered data\n",
    "df_filt = pd.read_csv(\"metadata_filt_180721.csv\", index_col=None)\n",
    "for prob in range(0,55,5):\n",
    "    for sigma in [0, 5]:\n",
    "        if not os.path.isfile(\"../coordinates/dcm/unilateral/dcm_{}mm_thres_{}.csv\".format(sigma, prob)):\n",
    "            prob_dcm(df_filt, prob, sigma=sigma, atlas=\"unilateral\", labs=labels_unilateral)\n",
    "        if not os.path.isfile(\"../coordinates/dcm/bilateral/dcm_{}mm_thres_{}.csv\".format(sigma, prob)):\n",
    "            prob_dcm(df_filt, prob, sigma=sigma, atlas=\"bilateral\", labs=labels_bilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24867712.txt\n",
      "999999992.txt\n"
     ]
    }
   ],
   "source": [
    "# List extra 5-mm coordinates\n",
    "for file in os.listdir(\"../coordinates/5mm\"):\n",
    "    if file not in os.listdir(\"../coordinates/0mm\"):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix left/right in smoothed coordinates\n",
    "dif_length, not_in_meta = [], []\n",
    "df_filt = pd.read_csv(\"metadata_filt_180721.csv\", index_col=None)\n",
    "for pmid in [file.replace(\".txt\", \"\") for file in os.listdir(\"../coordinates/5mm_raw\") if not file.startswith(\".\")]:\n",
    "    mappings = [line.strip() for line in open(\"../coordinates/5mm_raw/{}.txt\".format(pmid), \"r\").readlines()]\n",
    "    if int(pmid) in df_filt[\"PMID\"].values:\n",
    "        coords = list(df_filt[df_filt[\"PMID\"] == int(pmid)][\"MNI_COORDS\"])[0].split(\";\")\n",
    "        if len(mappings) != len(coords):\n",
    "            coords = sorted(set(coords), key=coords.index)\n",
    "            if len(mappings) != len(coords):\n",
    "                dif_length.append(pmid)\n",
    "            else:\n",
    "                for i, coord in enumerate(coords):\n",
    "                    if coord[0] == \"-\":\n",
    "                        mappings[i] = mappings[i].replace(\"right\", \"left\")\n",
    "                with open(\"../coordinates/5mm/{}.txt\".format(pmid), \"w+\") as outfile:\n",
    "                    for line in mappings:\n",
    "                          outfile.write(line + \"\\n\")\n",
    "        else:\n",
    "            for i, coord in enumerate(coords):\n",
    "                if coord[0] == \"-\":\n",
    "                    mappings[i] = mappings[i].replace(\"right\", \"left\")\n",
    "            with open(\"../coordinates/5mm/{}.txt\".format(pmid), \"w+\") as outfile:\n",
    "                for line in mappings:\n",
    "                      outfile.write(line + \"\\n\")\n",
    "    else:\n",
    "        not_in_meta.append(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns_ids = list(ns[\"id\"])\n",
    "bm_ids = list(bm['PMID'])\n",
    "ac_ids = list(ac[\"id\"])\n",
    "source = {}\n",
    "for pmid in dif_length:\n",
    "#     mappings = [line.strip() for line in open(\"../coordinates/5mm_raw/{}.txt\".format(pmid), \"r\").readlines()]\n",
    "#     coords = list(df_filt[df_filt[\"PMID\"] == int(pmid)][\"MNI_COORDS\"])[0].split(\";\")\n",
    "    source[pmid] = []\n",
    "    if int(pmid) in bm_ids:\n",
    "        source[pmid].append(\"brainmap\")\n",
    "    if int(pmid) in ns_ids:\n",
    "        source[pmid].append(\"neurosynth\")\n",
    "    if int(pmid) in ac_ids:\n",
    "        source[pmid].append(\"ace\")\n",
    "    \n",
    "    #print(\"{}: {} mappings, {} coordinates\".format(pmid, len(mappings), len(coords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pmid in dif_length + not_in_meta:\n",
    "    mappings = [line.strip() for line in open(\"../coordinates/5mm_raw/{}.txt\".format(pmid), \"r\").readlines()]\n",
    "    for i, mapping in enumerate(mappings):\n",
    "        if \"left\" in mapping:\n",
    "            mappings[i] = mapping.replace(\"right\", \"left\")\n",
    "    with open(\"../coordinates/5mm/{}.txt\".format(pmid), \"w+\") as outfile:\n",
    "        for line in mappings:\n",
    "            outfile.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
